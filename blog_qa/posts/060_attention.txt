
Transformers - Atenci贸n
Si hay un tema candente en el mundo del Deep Learning a d铆a de hoy, ese es sin duda el de los Transformers. Desde que esta arquitectura de redes neuronales fue introducida en 2017 en el art铆culo Attention is all you need nuevas aplicaciones aparecen cada d铆a en diferentes campos, mejorando el state of the art. Si bien el mayor impacto de los Transformers se ha visto en el campo del procesado de lenguaje natural, su aplicaci贸n en otros dominios (como el de la visi贸n artificial) no hace m谩s que crecer. Es debido a esta situaci贸n que me pregunto, 驴pero qu茅 es un Transformer?, 驴c贸mo funiona?, 驴en qu茅 se diferencia de otras arquitecturas como redes convolucionales o recurrentes? Con el objetivo de dar respuesta a estas preguntas, y muchas otras que surgir谩n por el camino, inicio una serie de posts para entender si realmente es oro todo lo que reluce.
Attention is all you need
Como comentaba en el p谩rrafo anterior, la arquitectura Transformer hizo su aparici贸n a escena en 2017 gracias al art铆culo Attention is all you need. El paper empieza as铆...

The dominant sequence transduction models are based on complex recurrent or
convolutional neural networks that include an encoder and a decoder. The best
performing models also connect the encoder and decoder through an attention
mechanism. We propose a new simple network architecture, the Transformer,
based solely on attention mechanisms, dispensing with recurrence and convolutions
entirely.

lo que traducido ser铆a algo as铆 como...

Los modelos secuenciales de transducci贸n dominantes est谩n basados en redes neuronales recurrentes o convolucionales complejas, las cuales incluyen un codificador y un decodificador. Los mejores modelos, adem谩s, conectan el codificador y el decodificador mediante un mecanismo de atenci贸n. Proponemos una nueva arquitectura simple, el Transformer, basado solamente en mecanismos de atenci贸n, haciendo innecesario el uso de recurrencia o convoluciones

A grandes rasgos, podemos ver que efectivamente se trata de una nueva arquitectura basada en algo llamado mecanismos de atenci贸n, y que no utiliza ni convoluciones ni recurrencia. En este post ya hablamos sobre este tema, sin embargo vamos ahora a entrar en detalle sobre lo que significa atenci贸n y como se implementa.
驴Qu茅 es la atenci贸n?
Un mecanismo de atenci贸n, en el contexto de las redes neuronales, consiste en una operaci贸n matem谩tica que recibe como inputs un conjunto de vectores (que ya sabemos que pueden representar texto, im谩genes o cualquier tipo de datos con el que trabajemos) y nos da como resultado otro conjunto de vectores. Este resultado depender谩, obviamente, del tipo de mecanismo de atenci贸n que utilizemos. Vamos a ver algunos ejemplos.
Hard attention
El mecanismo de atenci贸n m谩s sencillo de entender es el conocido como hard attention mechanism. En este tipo de atenci贸n generaremos un n煤mero de vectores a la salida igual a los de la entrada (de ahora en adelante asumiremos que este es siempre el caso a no ser que se indique lo contrario) en el que cada /blog/060/output atender谩 煤nicamente a su correspondiente vector a la entrada. O dicho de otra forma, este mecanismo de atenci贸n no produce nada nuevo, produce a la salida lo mismo que recibe a la entrada. Considera el conjunto de vectores siguiente.
import numpy as np
import torch
import matplotlib.pyplot as plt
import numpy as np

X = torch.tensor([[1, 0],[0, 1], [-0.5, -0.5]])
X

tensor([[ 1.0000,  0.0000],
        [ 0.0000,  1.0000],
        [-0.5000, -0.5000]])

def plot_vectors(X, y=None):
    ax = plt.axes()
    plt.grid()
    for x in X:
        ax.arrow(0, 0, x[0], x[1], head_width=0.1, head_length=0.1, color="white")
    if y is not None:
        for _y in y:
            if _y.sum() != 0:
                ax.arrow(0, 0, _y[0], _y[1], head_width=0.1, head_length=0.1, color='red')
    plt.xlim(-1,1.5)
    plt.ylim(-1,1.5)
    plt.show()

plot_vectors(X)


Un mecaniso de hard attention presatar谩 atenci贸n  a un 煤nico vector. Podemos representarlo como un vector en el que, en cada posici贸n, tenemos el peso relativo de cada vector a la entrada. En este caso, todos los valores ser谩n 0 excepto el que se encuentre en la mismo posici贸n del vector al que queremos prestar atenci贸n.
# hard attention (a es one hot)
# atendemos al primer vector
a = torch.tensor([1, 0, 0])
a

tensor([1, 0, 0])

Para aplicar nuestro mecanismo de atenci贸n, simplemente multiplicamos nuestro conjunto de vectores por el vector de atenci贸n.
# todos los vectores en la salida son 0, excepto al que hemos prestado atenci贸n

y = a.unsqueeze(1) * X
y

tensor([[1., 0.],
        [0., 0.],
        [-0., -0.]])

Podemos ver en rojo la salida de nuestro mecanismo de atenci贸n fuerte cuando atendemos al primer vector (es, efectivamente, igual al primer vector). Hemos prestado atenci贸n 煤nicamente a un elemento del conjunto, deshechando el resto.
plot_vectors(X, y)


Podemos aplicar este mecanismo en una sola operaci贸n a todos los vectores generando una matriz de atenci贸n. En el caso de hard attention, esta matriz es la identidad.
A = torch.eye(3)
A

tensor([[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]])

Multiplicando nuestra matriz de atenci贸n por la matriz que contiene todos los vectores de entrada, obtenemos los vectores de salida. En este caso, repetimos, obtendremos exactamente el mismo conjunto de vectores ya que cada vector a la salida atiene 煤nicamente a un vector a la entrada, aquel que est谩 en su misma posici贸n.
Y = A @ X
Y

tensor([[ 1.0000,  0.0000],
        [ 0.0000,  1.0000],
        [-0.5000, -0.5000]])

def plot(X, Y):
    fig = plt.figure(figsize=(15,4))
    for i, (x, y) in enumerate(zip(X, Y)):
      ax = plt.subplot(1, 3, i + 1)
      for x in X:
          ax.arrow(0, 0, x[0], x[1], head_width=0.1, color="white", head_length=0.1)
      ax.arrow(0, 0, y[0], y[1], head_width=0.1, head_length=0.1, color='red')
      ax.set_xlim(-1,1.5)
      ax.set_ylim(-1,1.5)
      ax.grid(True)
      ax.set_title(f"Atiende a {X[i].tolist()}")
    plt.tight_layout()
    plt.show()

plot(X, Y)


Soft attention
Ahora que hemos explicado qu茅 es un mecanismo de atenci贸n y visto un ejemplo sencillo, vamos a ver otro tipo de mecanismo un poco m谩s flexible. Si en el caso de la atenci贸n fuerte, cada vector generado presta atenci贸n simplemente a un 煤nico vector en la entrada, en el caso de la atenci贸n d茅bil vamos a permitir prestar atenci贸n a todos los vectores a la entrada. As铆 pues, cada vector generado ser谩 una combinaci贸n de los inputs. En el siguiente ejemplo, cada vector generado presta un 80% de atenci贸n al vector en la entrada en su misma posici贸n y un 10% al resto.
# soft attention (cada fila suma 1)

A = torch.ones((3, 3))*0.1
A.fill_diagonal_(0.8)
A

tensor([[0.8000, 0.1000, 0.1000],
        [0.1000, 0.8000, 0.1000],
        [0.1000, 0.1000, 0.8000]])

Y = A @ X
Y

tensor([[ 0.7500,  0.0500],
        [ 0.0500,  0.7500],
        [-0.3000, -0.3000]])

def plot(X, Y):
    fig = plt.figure(figsize=(15,4))
    for i, (x, y) in enumerate(zip(X, Y)):
      ax = plt.subplot(1, 3, i + 1)
      for x in X:
          ax.arrow(0, 0, x[0], x[1], color="white", head_width=0.1, head_length=0.1)
      Z = A[i].unsqueeze(1) * X
      for z in Z:
        ax.arrow(0, 0, z[0], z[1], head_width=0.1, head_length=0.1, color='green')
      ax.arrow(0, 0, y[0], y[1], head_width=0.1, head_length=0.1, color='red')
      ax.set_xlim(-1,1.5)
      ax.set_ylim(-1,1.5)
      ax.grid(True)
      ax.set_title(f"Atiende a {X[i].tolist()}")
    plt.tight_layout()
    plt.show()

plot(X, Y)


En verde puedes ver la contribuci贸n de cada vector al resultado, mientras que en rojo puedes ver los vectores generados por nuestro mecanismo de atenci贸n. En este caso, son muy similares a los originales ya que estamos prestando mucha atenci贸n a 茅stos mismo. Sin embargo, el resto de vectores pueden influir en el resultado. Vamos ahora a prestar igual atenci贸n a todos los vectores.
A = torch.ones((3, 3))*(1./3.)
A

tensor([[0.3333, 0.3333, 0.3333],
        [0.3333, 0.3333, 0.3333],
        [0.3333, 0.3333, 0.3333]])

Y = A @ X
Y

tensor([[0.1667, 0.1667],
        [0.1667, 0.1667],
        [0.1667, 0.1667]])

plot(X, Y)


En este caso, todos los vectores generados son iguales. La pregunta ahora es, 驴cu谩nta atenci贸n debe un vector prestar al resto? La respuesta es sencilla...Self attention !
Self attention
En este 煤ltimo mecanismo de atenci贸n que veremos, cada vector es responsable de decidir por si mismo cu谩nta atenci贸n prestar al resto. Para ello calcularemos la similitud entre vectores. Cuanto m谩s parecidos sean dos vectores, m谩s atenci贸n habr谩 entre ellos y viceversa. En una tarea de traducci贸n de texto, por ejemplo, a la hora de generar una palabra un mecanismo de self attention permitir铆a prestar m谩s atenci贸n a aquellas palabras m谩s relacionadas a la entrada, y no desperdiciar computaci贸n con aquellas que no tienen importancia. Esta similitud la calculamos multiplicando los vectores por si mismos y aplicando una funci贸n softmax.
# self attention -> similitud de cada vector con el resto

A = torch.softmax(X @ X.T, 1)
A

tensor([[0.6285, 0.2312, 0.1402],
        [0.2312, 0.6285, 0.1402],
        [0.2119, 0.2119, 0.5761]])

Y = A @ X
Y

tensor([[ 0.5584,  0.1611],
        [ 0.1611,  0.5584],
        [-0.0761, -0.0761]])

plot(X, Y)


Resumen
En este post hemos visto uno de los principales conceptos a la hora de trabajar con Transoformers: los mecanismos de atenci贸n. Hemos aprendido que estos mecanismos reciben conjuntos de vectores a su entrada y son responsables de generar otro a su salida. Este resultado depender谩 del mecanismo. En hard attention, cada vector generado presta atenci贸n 煤nicamente a un vector (aquel que se encuentra en su misma posici贸n a la entrada). En soft attention generamos vectores que son combinaciones de todos los vectores a la entrada. Por 煤ltimo, un mecanismo de self attention no es m谩s que un mecanismo de soft attention en el que la importancia de cada vector a la entrada depende de la similitud entre este y el resto de inputs. En los posts siguientes seguiremos adentr谩ndonos en el mundo de los Transformers, viendo otros conceptos importantes y sus implementaciones en Pytorch.

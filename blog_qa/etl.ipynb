{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook implementamos un asistente virtual para interactuar con mi blog: https://www.sensiocoders.com/blog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pinecone\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrapping"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recuperar lista de posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://www.sensiocoders.com/blog/\"  \n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "posts = soup.find_all('a', href=lambda href: href and \"/blog/\" in href)\n",
    "len(posts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Para cada post, extraemos el contenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 112/112 [00:27<00:00,  4.01it/s]\n"
     ]
    }
   ],
   "source": [
    "for post in tqdm(posts):\n",
    "\tpost_url = post['href'].split('/')[-1]\n",
    "\tpost_response = requests.get(url + post_url)\n",
    "\tpost_soup = BeautifulSoup(post_response.content, 'html.parser')\n",
    "\tcontent = post_soup.find('div', class_=\"post\").text \n",
    "\tos.makedirs('posts', exist_ok=True)\n",
    "\twith open(f'posts/{post_url}.txt', 'w') as f:\n",
    "\t\tf.write(content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos los embeddings de cada post y los guardamos en vector db."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings, OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma, Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_post(post):\n",
    "    with open('posts/' + post, 'r') as f:\n",
    "        return f.read()\n",
    "    \n",
    "posts = [read_post(post) for post in os.listdir('posts')]\n",
    "\n",
    "len(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15895.99107142857, 7516.431447520654, 5016, 37775)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "lens = [len(post) for post in posts]\n",
    "\n",
    "np.mean(lens), np.std(lens), np.min(lens), np.max(lens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cortamos los posts en trozos de tama√±o fijado para poder pasarselo al modelo sin pasarnos del l√≠mite de caracteres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 3149, which is longer than the specified 3000\n",
      "Created a chunk of size 6625, which is longer than the specified 3000\n",
      "Created a chunk of size 3229, which is longer than the specified 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 3257, which is longer than the specified 3000\n",
      "Created a chunk of size 7452, which is longer than the specified 3000\n",
      "Created a chunk of size 3849, which is longer than the specified 3000\n",
      "Created a chunk of size 5248, which is longer than the specified 3000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "316"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# text_splitter = CharacterTextSplitter(chunk_size=8192, chunk_overlap=256)\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=3000, chunk_overlap=0, disallowed_special=()\n",
    ")\n",
    "\n",
    "metadatas = [{\"source\": post} for post in os.listdir('posts')]\n",
    "documents = text_splitter.create_documents(posts, metadatas=metadatas)\n",
    "\n",
    "len(documents)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los embeddings de `HuggingFaceEmbeddings` son gratis, de tama√±o 768, pero no me han funcionado del todo bien. Los de `OpenAIEmbeddings` son de pago, de tama√±o 1536, pero funcionan mejor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embeddings = HuggingFaceEmbeddings() \n",
    "embeddings = OpenAIEmbeddings(openai_api_key=os.getenv('OPENAI_API_KEY'), disallowed_special=())\n",
    "\n",
    "text = \"Hola que tal?\"\n",
    "\n",
    "query_result = embeddings.embed_query(text)\n",
    "\n",
    "len(query_result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos usar `Chroma` para guardar los embeddings en local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comentado para evitar costes\n",
    "# vectorstore = Chroma.from_documents(documents, embeddings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Docs: https://api.python.langchain.com/en/latest/modules/vectorstores.html"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternativamente, `Pinecone` nos permite guardar los embeddings en la nube (gratis, con l√≠mites)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.init(api_key=os.environ['PINECONE_API_KEY'], environment=os.environ['PINECONE_ENVIRONMENT'])\n",
    "\n",
    "# index = pinecone.Index('blog-qa') \n",
    "# delete_response = index.delete(deleteAll=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generar la primera vez\n",
    "# vectorstore = Pinecone.from_documents(documents, embeddings, index_name='blog-qa')\n",
    "\n",
    "# una vez generados, se pueden cargar\n",
    "vectorstore = Pinecone.from_existing_index('blog-qa', embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Physics-Based Deep Learning\\nIntroducci√≥n\\nEste es el primero en una serie de posts en los que aprenderemos sobre PBDL: Physics-Based Deep Learning, o el uso del Deep Learning (redes neuronales) para simulaci√≥n f√≠sica. En concreto, nos centraremos en CFD: Computational Fluid Dynamics, el campo de la f√≠sica que se enfoca en la simulaci√≥n de fluidos para aplicaciones de aerodin√°mica, combusti√≥n, etc. Te advierto que nos vamos a alejar del machine learning tradicional para explorar un nuevo campo, el del uso de las redes neuronales para aproximar soluciones a ecuaciones diferenciales. Es posible que en algunos momentos te preguntes: ¬øes esto realmente machine learning? Te entiendo. A√∫n as√≠, creo firmemente que el campo del PBDL revolucionar√° la manera en la que simulamos la naturaleza en los pr√≥ximos a√±os, de la misma manera que el Deep Learning ha revolucionado (y lo sigue haciendo) tantos otros campos de la ciencia, como por ejemplo el plegado de proteinas.\\nEl campo del PBDL es una disciplina relativamente nueva e inexplorada que se basa el uso de redes neuronales para sustituir (o complementar) m√©todos num√©ricos \"tradicionales\" utilizados desde hace a√±os para simular los diferentes procesos f√≠sicos que rigen nuestra naturaleza (desde el comportamiento de nuestra atm√≥sfera hasta el movimiento de estrellas y galaxias). Estos procesos pueden ser descritos, en la mayor√≠a de ocasiones, mediante ecuaciones matem√°ticas. Resolver estas ecuaciones nos permite calcular, por ejemplo, la distribuci√≥n de presi√≥n sobre una superficie aerodin√°mica (lo cual es muy √∫til a la hora de dise√±ar aviones m√°s eficientes, entre muchas otras aplicaciones). Sin embargo, como te podr√°s imaginar, estas ecuaciones suelen ser muy dif√≠ciles de resolver y, en la mayor√≠a de situaciones, ni siquiera pueden ser resueltas de manera anal√≠tica. Es aqu√≠ donde entran en juego los m√©todos num√©ricos, t√©cnicas que nos permiten aproximar soluciones a estas ecuaciones que si bien no son exactas son lo suficientemente precisas para su uso en aplicaciones reales. Tradicionalmente, m√©todos num√©ricos de este estilo requieren de grandes recursos computacionales (es por este motivo que tenemos \"superordenadores\"). Por lo que cualquier avance en el campo que nos permita encontrar soluciones m√°s r√°pidas y baratas supone una revoluci√≥n. Creo que el campo del PBDL ser√° la siguiente revoluci√≥n en este campo. De hecho, este fue el motivo por el que me adentr√© en el mundo del Deep Learning, persiguiendo la idea de que usar redes neuronales para aproximar soluciones a ecuaciones diferenciales pod√≠a ser una buena idea.\\n\\nRecientemente se ha publicado este libro sobre PBDL. No dudes en consultarlo para aprender m√°s !\\n\\nComputational Fluid Dynamics\\nDentro del gran abanico de aplicaciones de la f√≠sica computacional, la mec√°nica de fluidos computacional se encarga del estudio del comportamiento de fluidos, principalmente mediante la resoluci√≥n de las ecuaciones de Navier-Stokes. Esto tiene un uso muy importante en el dise√±o de aeronaves, coches (muy importante en coches el√©ctricos), previsi√≥n meteorol√≥gica y an√°lisis de la evoluci√≥n de contaminantes, etc.\\n\\nComo ya he comentado anteriormente, resolver estas ecuaciones de manera anal√≠tica es imposible y su resoluci√≥n num√©rica require de grandes recursos computacionales. A√∫n as√≠, cada vez es m√°s extendido su uso. En el caso del sector aeron√°utico la alternativa es el uso de t√∫neles de viento, lo cual es todav√≠a m√°s caro y lento. Poder dise√±ar veh√≠culos con software de dise√±o 3d por ordenador, simular su comportamiento en varias condiciones e iterar su dise√±o hasta encontrar la geometr√≠a √≥ptima en entornos virtuales es una gran ventaja. Creo que el uso del Deep Learning para CFD supondr√° una revoluci√≥n y acelerar√°, a la vez que abaratar√°, todo este proceso dando como resultado veh√≠culos m√°s eficientes, que viajen m√°s r√°pido consumiendo y contaminando menos.\\n\\nSi quieres aprender m√°s sobre CFD te recomiendo echarle un vistazo a mi tesis doctoral ü§ó\\n\\nLeyes de Conservaci√≥n\\nIniciamos nuestro viaje en el campo del PBDL viendo el primer ejemplo de ecuaci√≥n diferencial que vamos a resolver, primero con m√©todos num√©ricos tradicionales y luego con redes neuronales. Nuestro objetivo final es el de resolver las ecuaciones de Navier-Stokes, las cuales se agrupan dentro de las leyes de conservaci√≥n. Una ley de conservaci√≥n explica la evoluci√≥n en el tiempo, \\nt\\n\\n\\n, y el espacio, \\nx\\n\\n\\n, de una variable conservativa. Un ejemplo muy simple es la evoluci√≥n de la masa, \\nm\\n\\n\\n, de un fluido en un dominio unidimensional.\\n\\n\\nm(t)  = \\\\int_{x_1}^{x_2} \\\\rho(x, t) dx\\n\\n\\nEn este caso, la magnitud conservativa es la densidad, \\n\\\\rho\\n\\n\\n. Asumiendo que ni se crea ni se destruye masa, su evoluci√≥n, \\nm(t)\\n\\n\\n, se deber√° √∫nicamente a la cantidad de fluido que est√© entrando y saliendo el dominio a trav√©s de la entrada, en \\nx_1\\n\\n\\n, y la salida, en \\nx_2\\n\\n\\n (lo que llamamos el flujo, \\nF\\n\\n\\n).\\n\\n\\n\\\\frac{\\\\partial}{\\\\partial t} \\\\int_{x_1}^{x_2} \\\\rho(x, t) dx = F_1(t) - F_2(t)\\n\\nDe conocer la velocidad del fluido, podr√≠amos calcular estos flujos como \\nf(\\\\rho(x,t)) = u(x,t)\\\\rho(x,t)\\n\\n.\\n\\n\\n\\\\frac{\\\\partial}{\\\\partial t} \\\\int_{x_1}^{x_2} \\\\rho(x, t) dx = f(\\\\rho(x_1,t)) - f(\\\\rho(x_2,t))\\n\\nManipulando esta ecuaci√≥n podemos derivar la siguiente ecuaci√≥n diferencial\\n\\n\\n\\\\frac{\\\\partial}{\\\\partial t} \\\\int_{x_1}^{x_2} \\\\rho(x, t) dx = - \\\\int_{x_1}^{x_2} \\\\frac{\\\\partial}{\\\\partial x} f(\\\\rho(x,t)) dx\\n\\nQue, reordenando, quedar√≠a como\\n\\n\\n\\\\int_{x_1}^{x_2} \\\\left[ \\\\frac{\\\\partial}{\\\\partial t} \\\\rho(x, t) + \\\\frac{\\\\partial}{\\\\partial x} f(\\\\rho(x,t)) \\\\right] dx = 0\\n\\n\\nY, debido a que esta integral tiene que ser cero para todos los valores de \\nx_1\\n\\n\\n y \\nx_2\\n\\n\\\\frac{\\\\partial}{\\\\partial t} \\\\rho(x, t) + \\\\frac{\\\\partial}{\\\\partial x} f(\\\\rho(x,t)) = 0\\n\\nEsta es la formulaci√≥n b√°sica de la ecuaci√≥n de conservaci√≥n de la masa. La forma general para una variable conservativa cualquiera se podr√≠a escribir como\\n\\n\\n\\\\frac{\\\\partial}{\\\\partial t} \\\\phi(x, t) + \\\\frac{\\\\partial}{\\\\partial x} f(\\\\phi(x,t)) = 0\\n\\nO, de manera m√°s compacta, simplemente\\n\\n\\n\\\\phi_t + f(\\\\phi)_x = 0\\n\\nM√©todos de Vol√∫menes Finitos\\nExisten multitud de m√©todos num√©ricos para resolver ecuaciones diferenciales (diferencias finitas, elementos finitos, m√©todos de Galerkin, ...). Para la resoluci√≥n de ecuaciones de conservaci√≥n, lo que nos interesa a nosotros, el uso de m√©todos de vol√∫menes finitos es el m√°s extendido debido a sus propiedades favorables.\\nEste m√©todo est√° basado en la discretizaci√≥n del dominio de inter√©s en el que queremos resolver nuestra ecuaci√≥n en una serie de celdas en las cuales representaremos nuestra soluci√≥n de manera promediada.\\n\\n\\n\\\\overline{\\\\phi}(x^k, t) = \\\\frac{1}{h^k} \\\\int_k \\\\phi(x, t) dx\\n\\n\\nY para satisfacer la ecuaci√≥n diferencial se debe cumplir que\\n\\n\\nh^k \\\\frac{\\\\partial \\\\overline{\\\\phi}(x^k)}{\\\\partial t} = f(x^{k - 1/2},t) - f(x^{k + 1/2},t)\\n\\nLo cual requerir√° el c√°lculo del flujo \\nf(x^{k \\\\pm 1/2}) = F(\\\\phi^k, \\\\phi^{k \\\\pm 1})\\n\\n.\\nLa ecuaci√≥n de convecci√≥n 1D\\nVamos a ver nuestro primer ejemplo de ecuaci√≥n diferencial: la ecuaci√≥n de convecci√≥n 1D.\\n\\n\\n\\\\phi_t + u \\\\phi_x = 0\\n\\nEn este caso, la variable conservativa es \\n\\\\phi(x, t)\\n\\n\\n y el flujo es \\nf(\\\\phi(x,t)) = u \\\\phi(x, t)\\n\\n\\n donde \\nu\\n\\n\\n es la velocidad, un valor escalar constante. Esta ecuaci√≥n es muy √∫til por varios motivos. En primer lugar, considerando condiciones de contorno peri√≥dicas, tiene soluci√≥n anal√≠tica\\n\\n\\n\\\\phi(x,t) = \\\\phi_0(x - ut)\\n\\ndonde \\n\\\\phi_0\\n\\n\\n es la condici√≥n inicial. A grandes rasgos, la condici√≥n inicial se propagar√° en \\nx\\n\\n\\n a la velocidad \\nu\\n\\n\\n. Esto convierte a la ecuaci√≥n de convecci√≥n 1D como un perfecto benchmark para probar diferentes m√©todos num√©ricos.\\nimport numpy as np\\nimport math\\nimport matplotlib.pyplot as plt\\n\\nx = np.linspace(0,1,100)\\np = np.sin(2*math.pi*x)\\n\\nplt.figure(dpi=100)\\nplt.plot(x, p)\\nplt.grid(True)\\nplt.xlabel(\\'x\\')\\nplt.ylabel(\\'$\\\\phi_0$\\')\\nplt.show()\\n\\n\\nfrom matplotlib import animation, rc\\nrc(\\'animation\\', html=\\'html5\\')', metadata={'source': '080_pbdl_intro.txt'}),\n",
       " Document(page_content='Resumen\\nEn este post hemos aprendido sobre el modelo de lenguaje Falcon, publicado recientemente y qu√© ha batido a otros modelos como GPT-3, PaLM y LLaMA en los benchmarks. La principal diferencia de Falcon con respecto a estos modelos es el uso de un dataset de 5 trillones de tokens extra√≠dos en su totalidad de internet (de los cuales solo se han usado 1.5 en su entrenamiento), que combinado con t√©cnicas de curado adecuadas, ha dado lugar a modelos con mejores prestaciones. Adem√°s, el modelo est√° disponible de manera libre y con una licencia Apache 2.0, lo que permite su uso para aplicaciones comerciales sin ning√∫n tipo de restricci√≥n o royalties. ¬°Ahora todo el mundo puede tener su ChatGPT sin ning√∫n tipo de restricciones ü•≥!', metadata={'source': '111_falcon.txt'}),\n",
       " Document(page_content='DLOps - Introducci√≥n\\nCon este post arrancamos una nueva serie en la que aprenderemos sobre DLOps. El t√©rmino DLOps es un derivado de DevOps, que a su vez hace referencia al conjunto de herramientas de software que nos ayudan al desarrollo y puesta en producci√≥n de c√≥digo asegurando su robustez y calidad durante todo el ciclo de vida. Si bien existen muchas herramientas y \"buenas pr√°cticas\" para DevOps, su uso en aplicaciones de Inteligencia Artificial no siempre es directo. Esto es debido a las diferencias fundamentales entre el software tradicional (software 1.0) y el machine learning (software 2.0). As√≠ pues, hablaremos sobre MLOps cuando nos refiramos a las herramientas que nos ayuden a desarrollar y poner en producci√≥n algoritmos de machine learning, o DLOps en el caso del deep learning. Estas herramientas incluir√°n, entre otras, la automatizaci√≥n en el entrenamiento de modelos, versionado de datasets, puesta en producci√≥n automatizada y monitoreo de modelos en producci√≥n.\\n\\nEsta serie est√° basada en este stack. Sin embargo, usar√© tecnolog√≠as alternativas en ciertos puntos y tambi√©n los har√© en otro orden que, en mi opini√≥n, tiene m√°s sentido y facilita las cosas. A√∫n as√≠, es un gran recurso para todos los interesados en aprender sobre DLOps.\\n\\nObjetivo\\nEl objetivo de esta serie ser√° el de montar, desde cero, una infraestructura completa de deep learning con especial foco en la automatizaci√≥n para que puedas aplicarlo a tus proyectos. Para ello, desarrollaremos un clasificador de im√°genes de d√≠gitos manuscritos usando el dataset MNIST. Este dataset es muy sencillo lo que nos permitir√° trabajar de manera r√°pida. En una aplicaci√≥n real, sin embargo, es posible que tengas que generar tu propio dataset recogiendo datos espec√≠ficos de tu aplicaci√≥n. El otro principal foco est√° puesto en la descentralizaci√≥n, de manera que esta infraestructura pueda ser implementada en equipos con responsabilidades separadas: mientras que un equipo de cient√≠ficos de datos trabaja en los datasets, recogiendo y etiquetando nuevas muestras, otro equipo de ingenieros podr√° trabajar en los modelos de manera separada y remota. Por otro lado, un equipo de QA minitorizar√° los modelos en producci√≥n para alertar de cualquier anomal√≠a.\\nNuestro primer dataset\\nEn primer lugar, descargaremos el dataset MNIST.\\nfrom sklearn.datasets import fetch_openml\\nfrom sklearn.model_selection import train_test_split\\n\\nX, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)\\n\\nX_train, X_test, y_train, y_test = train_test_split(\\n    X, y, test_size=10000\\n)\\n\\nlen(X_train), len(X_test), len(y_train), len(y_test)\\n\\n(60000, 10000, 60000, 10000)\\n\\nimport matplotlib.pyplot as plt\\nimport random\\n\\nfig = plt.figure(dpi=100)\\nfor ix in range(25):\\n    ax = plt.subplot(5, 5, ix + 1)\\n    i = random.randint(0, len(X_train)-1)\\n    img, label = X_train[i], y_train[i]\\n    ax.imshow(img.reshape(28,28), cmap=\\'gray\\')\\n    ax.set_title(label)\\n    ax.axis(\\'off\\')\\nplt.tight_layout()\\nplt.show()\\n\\n\\nEn nuestra primera iteraci√≥n, haremos un clasificador binario sencillo que detecte s√≥lo el n√∫mero 3. M√°s adelante iremos complicando los requisitos, lo cual nos dar√° opci√≥n a generar diferentes versiones de nuestro dataset y as√≠ ver un ejemplo de las herramientas necesarias para ello. Adem√°s, nos quedaremos con una peque√±a muestra para empezar con un dataset limitado.\\nimport numpy as np\\n\\nX_train_3 = X_train[y_train == \\'3\\'][:100]\\nX_train_no_3 = X_train[y_train != \\'3\\'][:100]\\n\\nlen(X_train_3), len(X_train_no_3)\\n\\n(100, 100)\\n\\ndef plot_samples(X):\\n    fig = plt.figure(dpi=100)\\n    for ix in range(25):\\n        ax = plt.subplot(5, 5, ix + 1)\\n        i = random.randint(0, len(X)-1)\\n        img = X[i]\\n        ax.imshow(img.reshape(28,28), cmap=\\'gray\\')\\n        ax.axis(\\'off\\')\\n    plt.tight_layout()\\n    plt.show()\\n\\nplot_samples(X_train_3)\\n\\n\\nplot_samples(X_train_no_3)\\n\\n\\nAhora guardaremos las im√°genes en sendas carpetas, separando adem√°s un 20% de las muestras para el conjunto de test. A medida que nuestra aplicaci√≥n vaya creciendo y siendo usada cada vez m√°s deberemos identificar aquellos ejemplos en los que falla, etiquetarlo e incluirlos en el conjunto de test. Por otro lado, deberemos recoger ejemplos similares, etiquetarlos y a√±adirlos al conjunto de entrenamiento. De este manera, al re-entrenar los modelos, nos aseguraremos de ir corrigiendo errores de manera adecuada (este proceso se conoce como active learning).\\nimport os\\nfrom pathlib import Path\\nfrom skimage.io import imsave\\nimport shutil\\n\\npath = Path(\\'dataset\\')\\n\\ndef generate_dataset(X_train_3, X_train_no_3, test_size):\\n    shutil.rmtree(path)\\n    os.makedirs(path, exist_ok=True)\\n\\n    splits = [\\'train\\', \\'test\\']\\n    for split in splits:\\n        os.makedirs(path / split, exist_ok=True)\\n        os.makedirs(path / split / \\'3\\', exist_ok=True)\\n        os.makedirs(path / split / \\'no3\\', exist_ok=True)\\n        if split == \\'train\\':\\n            X1, X2 = X_train_3[:-test_size], X_train_no_3[:-test_size]\\n        else:\\n            X1, X2 = X_train_3[-test_size:], X_train_no_3[-test_size:]\\n        for x1, x2 in zip(X1, X2):\\n            imsave(path / split / \\'3\\' / f\\'{random.randint(0, 99999):05d}.png\\', x1.reshape(28,28).astype(\\'uint8\\'))\\n            imsave(path / split / \\'no3\\' / f\\'{random.randint(0, 99999):05d}.png\\', x2.reshape(28,28).astype(\\'uint8\\'))\\n\\n\\ngenerate_dataset(X_train_3, X_train_no_3, 20)\\n\\nfrom glob import glob\\n\\ndef get_paths():\\n    train_3 = glob(str(path / \\'train\\' / \\'3\\' / \\'*.png\\'))\\n    train_no3 = glob(str(path / \\'train\\' / \\'no3\\' / \\'*.png\\'))\\n    test_3 = glob(str(path / \\'test\\' / \\'3\\' / \\'*.png\\'))\\n    test_no3 = glob(str(path / \\'test\\' / \\'no3\\' / \\'*.png\\'))\\n    return train_3, train_no3, test_3, test_no3\\n\\ntrain_3, train_no3, test_3, test_no3 = get_paths()\\n\\nlen(train_3), len(train_no3), len(test_3), len(test_no3)\\n\\n(80, 80, 20, 20)\\n\\nfrom skimage.io import imread\\n\\ndef plot_images(paths):\\n    fig = plt.figure(dpi=100)\\n    for ix in range(25):\\n        ax = plt.subplot(5, 5, ix + 1)\\n        i = random.randint(0, len(paths)-1)\\n        img = imread(paths[i])\\n        ax.imshow(img, cmap=\\'gray\\')\\n        ax.axis(\\'off\\')\\n    plt.tight_layout()\\n    plt.show()\\n\\nplot_images(train_3)\\n\\n\\nplot_images(train_no3)\\n\\n\\nVersionado de datos\\nEn este punto hemos generado una primera versi√≥n de nuestro dataset que queremos usar para entrenar nuestro primero modelo. Sabemos que en el futuro el dataset ir√° evolucionando, a√±adiendo m√°s ejemplos y clases (y en funci√≥n de la aplicaci√≥n potencialmente nuevas tareas). La opci√≥n m√°s sencilla para manejar esto ser√≠a generar un .zip con nuestros datos, ponerle un nombre (por ejemplo, mnist-v1.0) y guardarlo en alg√∫n servidor al cual puedan acceder los ingeniero de deep learning para entrenar modelos. Lo mismo podr√≠amos hacer en el software 1.0 con nuestro c√≥digo (y durante mucho tiempo as√≠ se hizo, incluso quiz√°s hay empresas que a√∫n lo hacen üòÇ) sin embargo hace tiempo que aprendimos que el uso de herramientas de control de versi√≥n son mucho m√°s √∫tiles y eficaces. El ejemplo principal es git. As√≠ pues, para manejar nuestros datos (y m√°s adelante modelos, m√©tricas e incluso pipelines de entrenamiento) usaremos una herramienta de control de versi√≥n espec√≠fica para trabajar con grandes datos en entornos de machine learning conocida como dvc. dvc trabaja en conjunto con git, as√≠ que lo primero que necesitaremos ser√° un repositorio de git, que puedes alojar en Github, para manejar el proyecto.\\n\\nEn mi caso he creado este repo que usar√© durante toda la serie de posts.\\n\\nPuedes instalar dvc con el siguiente comando:\\npip install dvc', metadata={'source': '087_dlops_intro.txt'})]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'que es el PBDL?'\n",
    "\n",
    "docs = vectorstore.similarity_search(query, k=3)\n",
    "\n",
    "docs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QA pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The LLM model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez preparados los datos, procedemos a instanciar el LLM que queramos usar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/.local/lib/python3.10/site-packages/langchain/llms/openai.py:171: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/home/juan/.local/lib/python3.10/site-packages/langchain/llms/openai.py:716: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain import HuggingFacePipeline, HuggingFaceHub, OpenAI\n",
    "import torch\n",
    "\n",
    "model = \"tiiuae/falcon-40b-instruct\"\n",
    "\n",
    "# modelos HF en local\n",
    "# llm = HuggingFacePipeline.from_model_id(\n",
    "#     model_id=model, \n",
    "#     task=\"text-generation\", \n",
    "#     model_kwargs={\n",
    "#         \"max_length\": 2048, # debe incluir documentos\n",
    "#         'device_map': 'auto',\n",
    "#         'trust_remote_code': True,\n",
    "#         'torch_dtype': torch.bfloat16\n",
    "# \t}\n",
    "# )\n",
    "\n",
    "# modelos HF en la nube\n",
    "# llm = HuggingFaceHub(repo_id=model, model_kwargs={\"temperature\": 0.1, \"max_length\": 2048})\n",
    "\n",
    "# modelos OpenAI\n",
    "llm = OpenAI(model_name='gpt-3.5-turbo', temperature=0, openai_api_key=os.environ['OPENAI_API_KEY'], max_tokens=256)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opcionalmente, podemos modificar los prompts para que se adapten mejor a nuestro caso de uso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "# este es el prompt que se usar√° para generar las respuestas\n",
    "\n",
    "template = \"\"\"Dado el siguiente contexto, reponde la pregunta.\n",
    "Si no sabes la respuesta, responde con \"No lo s√©\". \n",
    "No inventes respuestas.\n",
    "Responde siempre en espa√±ol.\n",
    "\n",
    "Contexto:\n",
    "\n",
    "{context} \n",
    "\n",
    "Pregunta:\n",
    "\n",
    "{question}\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=['context', 'question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# este es el prompt que se usar√° cuando usemos contexto de chat (el prompt anterior se ejectuar√° despu√©s)\n",
    "\n",
    "template = \"\"\"Dado el siguiente historial de conversaci√≥n, reformula la pregunta de forma que el modelo pueda responderla:\n",
    "\n",
    "Historial:\n",
    "\n",
    "{chat_history}\n",
    "\n",
    "Pregunta:\n",
    "\n",
    "{question}\n",
    "\n",
    "Progunta reformulada:\"\"\"\n",
    "\n",
    "condense_question_prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos la `chain`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm, \n",
    "    vectorstore.as_retriever(search_kwargs={'k': 1}), \n",
    "    return_source_documents=True, \n",
    "    condense_question_prompt=condense_question_prompt, \n",
    "    combine_docs_chain_kwargs={'prompt': prompt}\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'El PBDL es el uso del Deep Learning (redes neuronales) para simulaci√≥n f√≠sica, en concreto, se centra en CFD: Computational Fluid Dynamics, el campo de la f√≠sica que se enfoca en la simulaci√≥n de fluidos para aplicaciones de aerodin√°mica, combusti√≥n, etc.'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history = []\n",
    "query = \"Que es el PBDL?\"\n",
    "result = qa({\"question\": query, \"chat_history\": chat_history})\n",
    "result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['080_pbdl_intro.txt']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[source.metadata['source'] for source in result['source_documents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'El uso del PBDL en la simulaci√≥n de fluidos para aplicaciones de aerodin√°mica, combusti√≥n, etc. supone una revoluci√≥n y acelerar√°, a la vez que abaratar√°, todo el proceso de dise√±o de veh√≠culos, dando como resultado veh√≠culos m√°s eficientes, que viajen m√°s r√°pido consumiendo y contaminando menos.'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.append((query, result[\"answer\"]))\n",
    "query = \"Que ventajas ofrece?\"\n",
    "result = qa({\"question\": query, \"chat_history\": chat_history})\n",
    "result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['080_pbdl_intro.txt']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[source.metadata['source'] for source in result['source_documents']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya lo tenemos todo listo para implementar una API con la que interactuar con el blog a trav√©s d elenguaje natural (ver script adjunto)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ideas de mejoras"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Agregar transcripciones de v√≠deos de youtube\n",
    "- Agregar funcionalidad de voz\n",
    "- Automatizar ETL (cronjob)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook implementamos un asistente virtual para interactuar con mi blog: https://www.sensiocoders.com/blog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pinecone\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrapping"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recuperar lista de posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://www.sensiocoders.com/blog/\"  \n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "posts = soup.find_all('a', href=lambda href: href and \"/blog/\" in href)\n",
    "len(posts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Para cada post, extraemos el contenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:27<00:00,  4.01it/s]\n"
     ]
    }
   ],
   "source": [
    "for post in tqdm(posts):\n",
    "\tpost_url = post['href'].split('/')[-1]\n",
    "\tpost_response = requests.get(url + post_url)\n",
    "\tpost_soup = BeautifulSoup(post_response.content, 'html.parser')\n",
    "\tcontent = post_soup.find('div', class_=\"post\").text \n",
    "\tos.makedirs('posts', exist_ok=True)\n",
    "\twith open(f'posts/{post_url}.txt', 'w') as f:\n",
    "\t\tf.write(content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos los embeddings de cada post y los guardamos en vector db."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings, OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma, Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_post(post):\n",
    "    with open('posts/' + post, 'r') as f:\n",
    "        return f.read()\n",
    "    \n",
    "posts = [read_post(post) for post in os.listdir('posts')]\n",
    "\n",
    "len(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15895.99107142857, 7516.431447520654, 5016, 37775)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "lens = [len(post) for post in posts]\n",
    "\n",
    "np.mean(lens), np.std(lens), np.min(lens), np.max(lens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cortamos los posts en trozos de tamaño fijado para poder pasarselo al modelo sin pasarnos del límite de caracteres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 3149, which is longer than the specified 3000\n",
      "Created a chunk of size 6625, which is longer than the specified 3000\n",
      "Created a chunk of size 3229, which is longer than the specified 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 3257, which is longer than the specified 3000\n",
      "Created a chunk of size 7452, which is longer than the specified 3000\n",
      "Created a chunk of size 3849, which is longer than the specified 3000\n",
      "Created a chunk of size 5248, which is longer than the specified 3000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "316"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# text_splitter = CharacterTextSplitter(chunk_size=8192, chunk_overlap=256)\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=3000, chunk_overlap=0, disallowed_special=()\n",
    ")\n",
    "\n",
    "metadatas = [{\"source\": post} for post in os.listdir('posts')]\n",
    "documents = text_splitter.create_documents(posts, metadatas=metadatas)\n",
    "\n",
    "len(documents)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los embeddings de `HuggingFaceEmbeddings` son gratis, de tamaño 768, pero no me han funcionado del todo bien. Los de `OpenAIEmbeddings` son de pago, de tamaño 1536, pero funcionan mejor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embeddings = HuggingFaceEmbeddings() \n",
    "embeddings = OpenAIEmbeddings(openai_api_key=os.getenv('OPENAI_API_KEY'), disallowed_special=())\n",
    "\n",
    "text = \"Hola que tal?\"\n",
    "\n",
    "query_result = embeddings.embed_query(text)\n",
    "\n",
    "len(query_result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos usar `Chroma` para guardar los embeddings en local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comentado para evitar costes\n",
    "# vectorstore = Chroma.from_documents(documents, embeddings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Docs: https://api.python.langchain.com/en/latest/modules/vectorstores.html"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternativamente, `Pinecone` nos permite guardar los embeddings en la nube (gratis, con límites)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.init(api_key=os.environ['PINECONE_API_KEY'], environment=os.environ['PINECONE_ENVIRONMENT'])\n",
    "\n",
    "# index = pinecone.Index('blog-qa') \n",
    "# delete_response = index.delete(deleteAll=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generar la primera vez\n",
    "# vectorstore = Pinecone.from_documents(documents, embeddings, index_name='blog-qa')\n",
    "\n",
    "# una vez generados, se pueden cargar\n",
    "vectorstore = Pinecone.from_existing_index('blog-qa', embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Physics-Based Deep Learning\\nIntroducción\\nEste es el primero en una serie de posts en los que aprenderemos sobre PBDL: Physics-Based Deep Learning, o el uso del Deep Learning (redes neuronales) para simulación física. En concreto, nos centraremos en CFD: Computational Fluid Dynamics, el campo de la física que se enfoca en la simulación de fluidos para aplicaciones de aerodinámica, combustión, etc. Te advierto que nos vamos a alejar del machine learning tradicional para explorar un nuevo campo, el del uso de las redes neuronales para aproximar soluciones a ecuaciones diferenciales. Es posible que en algunos momentos te preguntes: ¿es esto realmente machine learning? Te entiendo. Aún así, creo firmemente que el campo del PBDL revolucionará la manera en la que simulamos la naturaleza en los próximos años, de la misma manera que el Deep Learning ha revolucionado (y lo sigue haciendo) tantos otros campos de la ciencia, como por ejemplo el plegado de proteinas.\\nEl campo del PBDL es una disciplina relativamente nueva e inexplorada que se basa el uso de redes neuronales para sustituir (o complementar) métodos numéricos \"tradicionales\" utilizados desde hace años para simular los diferentes procesos físicos que rigen nuestra naturaleza (desde el comportamiento de nuestra atmósfera hasta el movimiento de estrellas y galaxias). Estos procesos pueden ser descritos, en la mayoría de ocasiones, mediante ecuaciones matemáticas. Resolver estas ecuaciones nos permite calcular, por ejemplo, la distribución de presión sobre una superficie aerodinámica (lo cual es muy útil a la hora de diseñar aviones más eficientes, entre muchas otras aplicaciones). Sin embargo, como te podrás imaginar, estas ecuaciones suelen ser muy difíciles de resolver y, en la mayoría de situaciones, ni siquiera pueden ser resueltas de manera analítica. Es aquí donde entran en juego los métodos numéricos, técnicas que nos permiten aproximar soluciones a estas ecuaciones que si bien no son exactas son lo suficientemente precisas para su uso en aplicaciones reales. Tradicionalmente, métodos numéricos de este estilo requieren de grandes recursos computacionales (es por este motivo que tenemos \"superordenadores\"). Por lo que cualquier avance en el campo que nos permita encontrar soluciones más rápidas y baratas supone una revolución. Creo que el campo del PBDL será la siguiente revolución en este campo. De hecho, este fue el motivo por el que me adentré en el mundo del Deep Learning, persiguiendo la idea de que usar redes neuronales para aproximar soluciones a ecuaciones diferenciales podía ser una buena idea.\\n\\nRecientemente se ha publicado este libro sobre PBDL. No dudes en consultarlo para aprender más !\\n\\nComputational Fluid Dynamics\\nDentro del gran abanico de aplicaciones de la física computacional, la mecánica de fluidos computacional se encarga del estudio del comportamiento de fluidos, principalmente mediante la resolución de las ecuaciones de Navier-Stokes. Esto tiene un uso muy importante en el diseño de aeronaves, coches (muy importante en coches eléctricos), previsión meteorológica y análisis de la evolución de contaminantes, etc.\\n\\nComo ya he comentado anteriormente, resolver estas ecuaciones de manera analítica es imposible y su resolución numérica require de grandes recursos computacionales. Aún así, cada vez es más extendido su uso. En el caso del sector aeronáutico la alternativa es el uso de túneles de viento, lo cual es todavía más caro y lento. Poder diseñar vehículos con software de diseño 3d por ordenador, simular su comportamiento en varias condiciones e iterar su diseño hasta encontrar la geometría óptima en entornos virtuales es una gran ventaja. Creo que el uso del Deep Learning para CFD supondrá una revolución y acelerará, a la vez que abaratará, todo este proceso dando como resultado vehículos más eficientes, que viajen más rápido consumiendo y contaminando menos.\\n\\nSi quieres aprender más sobre CFD te recomiendo echarle un vistazo a mi tesis doctoral 🤗\\n\\nLeyes de Conservación\\nIniciamos nuestro viaje en el campo del PBDL viendo el primer ejemplo de ecuación diferencial que vamos a resolver, primero con métodos numéricos tradicionales y luego con redes neuronales. Nuestro objetivo final es el de resolver las ecuaciones de Navier-Stokes, las cuales se agrupan dentro de las leyes de conservación. Una ley de conservación explica la evolución en el tiempo, \\nt\\n\\n\\n, y el espacio, \\nx\\n\\n\\n, de una variable conservativa. Un ejemplo muy simple es la evolución de la masa, \\nm\\n\\n\\n, de un fluido en un dominio unidimensional.\\n\\n\\nm(t)  = \\\\int_{x_1}^{x_2} \\\\rho(x, t) dx\\n\\n\\nEn este caso, la magnitud conservativa es la densidad, \\n\\\\rho\\n\\n\\n. Asumiendo que ni se crea ni se destruye masa, su evolución, \\nm(t)\\n\\n\\n, se deberá únicamente a la cantidad de fluido que esté entrando y saliendo el dominio a través de la entrada, en \\nx_1\\n\\n\\n, y la salida, en \\nx_2\\n\\n\\n (lo que llamamos el flujo, \\nF\\n\\n\\n).\\n\\n\\n\\\\frac{\\\\partial}{\\\\partial t} \\\\int_{x_1}^{x_2} \\\\rho(x, t) dx = F_1(t) - F_2(t)\\n\\nDe conocer la velocidad del fluido, podríamos calcular estos flujos como \\nf(\\\\rho(x,t)) = u(x,t)\\\\rho(x,t)\\n\\n.\\n\\n\\n\\\\frac{\\\\partial}{\\\\partial t} \\\\int_{x_1}^{x_2} \\\\rho(x, t) dx = f(\\\\rho(x_1,t)) - f(\\\\rho(x_2,t))\\n\\nManipulando esta ecuación podemos derivar la siguiente ecuación diferencial\\n\\n\\n\\\\frac{\\\\partial}{\\\\partial t} \\\\int_{x_1}^{x_2} \\\\rho(x, t) dx = - \\\\int_{x_1}^{x_2} \\\\frac{\\\\partial}{\\\\partial x} f(\\\\rho(x,t)) dx\\n\\nQue, reordenando, quedaría como\\n\\n\\n\\\\int_{x_1}^{x_2} \\\\left[ \\\\frac{\\\\partial}{\\\\partial t} \\\\rho(x, t) + \\\\frac{\\\\partial}{\\\\partial x} f(\\\\rho(x,t)) \\\\right] dx = 0\\n\\n\\nY, debido a que esta integral tiene que ser cero para todos los valores de \\nx_1\\n\\n\\n y \\nx_2\\n\\n\\\\frac{\\\\partial}{\\\\partial t} \\\\rho(x, t) + \\\\frac{\\\\partial}{\\\\partial x} f(\\\\rho(x,t)) = 0\\n\\nEsta es la formulación básica de la ecuación de conservación de la masa. La forma general para una variable conservativa cualquiera se podría escribir como\\n\\n\\n\\\\frac{\\\\partial}{\\\\partial t} \\\\phi(x, t) + \\\\frac{\\\\partial}{\\\\partial x} f(\\\\phi(x,t)) = 0\\n\\nO, de manera más compacta, simplemente\\n\\n\\n\\\\phi_t + f(\\\\phi)_x = 0\\n\\nMétodos de Volúmenes Finitos\\nExisten multitud de métodos numéricos para resolver ecuaciones diferenciales (diferencias finitas, elementos finitos, métodos de Galerkin, ...). Para la resolución de ecuaciones de conservación, lo que nos interesa a nosotros, el uso de métodos de volúmenes finitos es el más extendido debido a sus propiedades favorables.\\nEste método está basado en la discretización del dominio de interés en el que queremos resolver nuestra ecuación en una serie de celdas en las cuales representaremos nuestra solución de manera promediada.\\n\\n\\n\\\\overline{\\\\phi}(x^k, t) = \\\\frac{1}{h^k} \\\\int_k \\\\phi(x, t) dx\\n\\n\\nY para satisfacer la ecuación diferencial se debe cumplir que\\n\\n\\nh^k \\\\frac{\\\\partial \\\\overline{\\\\phi}(x^k)}{\\\\partial t} = f(x^{k - 1/2},t) - f(x^{k + 1/2},t)\\n\\nLo cual requerirá el cálculo del flujo \\nf(x^{k \\\\pm 1/2}) = F(\\\\phi^k, \\\\phi^{k \\\\pm 1})\\n\\n.\\nLa ecuación de convección 1D\\nVamos a ver nuestro primer ejemplo de ecuación diferencial: la ecuación de convección 1D.\\n\\n\\n\\\\phi_t + u \\\\phi_x = 0\\n\\nEn este caso, la variable conservativa es \\n\\\\phi(x, t)\\n\\n\\n y el flujo es \\nf(\\\\phi(x,t)) = u \\\\phi(x, t)\\n\\n\\n donde \\nu\\n\\n\\n es la velocidad, un valor escalar constante. Esta ecuación es muy útil por varios motivos. En primer lugar, considerando condiciones de contorno periódicas, tiene solución analítica\\n\\n\\n\\\\phi(x,t) = \\\\phi_0(x - ut)\\n\\ndonde \\n\\\\phi_0\\n\\n\\n es la condición inicial. A grandes rasgos, la condición inicial se propagará en \\nx\\n\\n\\n a la velocidad \\nu\\n\\n\\n. Esto convierte a la ecuación de convección 1D como un perfecto benchmark para probar diferentes métodos numéricos.\\nimport numpy as np\\nimport math\\nimport matplotlib.pyplot as plt\\n\\nx = np.linspace(0,1,100)\\np = np.sin(2*math.pi*x)\\n\\nplt.figure(dpi=100)\\nplt.plot(x, p)\\nplt.grid(True)\\nplt.xlabel(\\'x\\')\\nplt.ylabel(\\'$\\\\phi_0$\\')\\nplt.show()\\n\\n\\nfrom matplotlib import animation, rc\\nrc(\\'animation\\', html=\\'html5\\')', metadata={'source': '080_pbdl_intro.txt'}),\n",
       " Document(page_content='Resumen\\nEn este post hemos aprendido sobre el modelo de lenguaje Falcon, publicado recientemente y qué ha batido a otros modelos como GPT-3, PaLM y LLaMA en los benchmarks. La principal diferencia de Falcon con respecto a estos modelos es el uso de un dataset de 5 trillones de tokens extraídos en su totalidad de internet (de los cuales solo se han usado 1.5 en su entrenamiento), que combinado con técnicas de curado adecuadas, ha dado lugar a modelos con mejores prestaciones. Además, el modelo está disponible de manera libre y con una licencia Apache 2.0, lo que permite su uso para aplicaciones comerciales sin ningún tipo de restricción o royalties. ¡Ahora todo el mundo puede tener su ChatGPT sin ningún tipo de restricciones 🥳!', metadata={'source': '111_falcon.txt'}),\n",
       " Document(page_content='DLOps - Introducción\\nCon este post arrancamos una nueva serie en la que aprenderemos sobre DLOps. El término DLOps es un derivado de DevOps, que a su vez hace referencia al conjunto de herramientas de software que nos ayudan al desarrollo y puesta en producción de código asegurando su robustez y calidad durante todo el ciclo de vida. Si bien existen muchas herramientas y \"buenas prácticas\" para DevOps, su uso en aplicaciones de Inteligencia Artificial no siempre es directo. Esto es debido a las diferencias fundamentales entre el software tradicional (software 1.0) y el machine learning (software 2.0). Así pues, hablaremos sobre MLOps cuando nos refiramos a las herramientas que nos ayuden a desarrollar y poner en producción algoritmos de machine learning, o DLOps en el caso del deep learning. Estas herramientas incluirán, entre otras, la automatización en el entrenamiento de modelos, versionado de datasets, puesta en producción automatizada y monitoreo de modelos en producción.\\n\\nEsta serie está basada en este stack. Sin embargo, usaré tecnologías alternativas en ciertos puntos y también los haré en otro orden que, en mi opinión, tiene más sentido y facilita las cosas. Aún así, es un gran recurso para todos los interesados en aprender sobre DLOps.\\n\\nObjetivo\\nEl objetivo de esta serie será el de montar, desde cero, una infraestructura completa de deep learning con especial foco en la automatización para que puedas aplicarlo a tus proyectos. Para ello, desarrollaremos un clasificador de imágenes de dígitos manuscritos usando el dataset MNIST. Este dataset es muy sencillo lo que nos permitirá trabajar de manera rápida. En una aplicación real, sin embargo, es posible que tengas que generar tu propio dataset recogiendo datos específicos de tu aplicación. El otro principal foco está puesto en la descentralización, de manera que esta infraestructura pueda ser implementada en equipos con responsabilidades separadas: mientras que un equipo de científicos de datos trabaja en los datasets, recogiendo y etiquetando nuevas muestras, otro equipo de ingenieros podrá trabajar en los modelos de manera separada y remota. Por otro lado, un equipo de QA minitorizará los modelos en producción para alertar de cualquier anomalía.\\nNuestro primer dataset\\nEn primer lugar, descargaremos el dataset MNIST.\\nfrom sklearn.datasets import fetch_openml\\nfrom sklearn.model_selection import train_test_split\\n\\nX, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)\\n\\nX_train, X_test, y_train, y_test = train_test_split(\\n    X, y, test_size=10000\\n)\\n\\nlen(X_train), len(X_test), len(y_train), len(y_test)\\n\\n(60000, 10000, 60000, 10000)\\n\\nimport matplotlib.pyplot as plt\\nimport random\\n\\nfig = plt.figure(dpi=100)\\nfor ix in range(25):\\n    ax = plt.subplot(5, 5, ix + 1)\\n    i = random.randint(0, len(X_train)-1)\\n    img, label = X_train[i], y_train[i]\\n    ax.imshow(img.reshape(28,28), cmap=\\'gray\\')\\n    ax.set_title(label)\\n    ax.axis(\\'off\\')\\nplt.tight_layout()\\nplt.show()\\n\\n\\nEn nuestra primera iteración, haremos un clasificador binario sencillo que detecte sólo el número 3. Más adelante iremos complicando los requisitos, lo cual nos dará opción a generar diferentes versiones de nuestro dataset y así ver un ejemplo de las herramientas necesarias para ello. Además, nos quedaremos con una pequeña muestra para empezar con un dataset limitado.\\nimport numpy as np\\n\\nX_train_3 = X_train[y_train == \\'3\\'][:100]\\nX_train_no_3 = X_train[y_train != \\'3\\'][:100]\\n\\nlen(X_train_3), len(X_train_no_3)\\n\\n(100, 100)\\n\\ndef plot_samples(X):\\n    fig = plt.figure(dpi=100)\\n    for ix in range(25):\\n        ax = plt.subplot(5, 5, ix + 1)\\n        i = random.randint(0, len(X)-1)\\n        img = X[i]\\n        ax.imshow(img.reshape(28,28), cmap=\\'gray\\')\\n        ax.axis(\\'off\\')\\n    plt.tight_layout()\\n    plt.show()\\n\\nplot_samples(X_train_3)\\n\\n\\nplot_samples(X_train_no_3)\\n\\n\\nAhora guardaremos las imágenes en sendas carpetas, separando además un 20% de las muestras para el conjunto de test. A medida que nuestra aplicación vaya creciendo y siendo usada cada vez más deberemos identificar aquellos ejemplos en los que falla, etiquetarlo e incluirlos en el conjunto de test. Por otro lado, deberemos recoger ejemplos similares, etiquetarlos y añadirlos al conjunto de entrenamiento. De este manera, al re-entrenar los modelos, nos aseguraremos de ir corrigiendo errores de manera adecuada (este proceso se conoce como active learning).\\nimport os\\nfrom pathlib import Path\\nfrom skimage.io import imsave\\nimport shutil\\n\\npath = Path(\\'dataset\\')\\n\\ndef generate_dataset(X_train_3, X_train_no_3, test_size):\\n    shutil.rmtree(path)\\n    os.makedirs(path, exist_ok=True)\\n\\n    splits = [\\'train\\', \\'test\\']\\n    for split in splits:\\n        os.makedirs(path / split, exist_ok=True)\\n        os.makedirs(path / split / \\'3\\', exist_ok=True)\\n        os.makedirs(path / split / \\'no3\\', exist_ok=True)\\n        if split == \\'train\\':\\n            X1, X2 = X_train_3[:-test_size], X_train_no_3[:-test_size]\\n        else:\\n            X1, X2 = X_train_3[-test_size:], X_train_no_3[-test_size:]\\n        for x1, x2 in zip(X1, X2):\\n            imsave(path / split / \\'3\\' / f\\'{random.randint(0, 99999):05d}.png\\', x1.reshape(28,28).astype(\\'uint8\\'))\\n            imsave(path / split / \\'no3\\' / f\\'{random.randint(0, 99999):05d}.png\\', x2.reshape(28,28).astype(\\'uint8\\'))\\n\\n\\ngenerate_dataset(X_train_3, X_train_no_3, 20)\\n\\nfrom glob import glob\\n\\ndef get_paths():\\n    train_3 = glob(str(path / \\'train\\' / \\'3\\' / \\'*.png\\'))\\n    train_no3 = glob(str(path / \\'train\\' / \\'no3\\' / \\'*.png\\'))\\n    test_3 = glob(str(path / \\'test\\' / \\'3\\' / \\'*.png\\'))\\n    test_no3 = glob(str(path / \\'test\\' / \\'no3\\' / \\'*.png\\'))\\n    return train_3, train_no3, test_3, test_no3\\n\\ntrain_3, train_no3, test_3, test_no3 = get_paths()\\n\\nlen(train_3), len(train_no3), len(test_3), len(test_no3)\\n\\n(80, 80, 20, 20)\\n\\nfrom skimage.io import imread\\n\\ndef plot_images(paths):\\n    fig = plt.figure(dpi=100)\\n    for ix in range(25):\\n        ax = plt.subplot(5, 5, ix + 1)\\n        i = random.randint(0, len(paths)-1)\\n        img = imread(paths[i])\\n        ax.imshow(img, cmap=\\'gray\\')\\n        ax.axis(\\'off\\')\\n    plt.tight_layout()\\n    plt.show()\\n\\nplot_images(train_3)\\n\\n\\nplot_images(train_no3)\\n\\n\\nVersionado de datos\\nEn este punto hemos generado una primera versión de nuestro dataset que queremos usar para entrenar nuestro primero modelo. Sabemos que en el futuro el dataset irá evolucionando, añadiendo más ejemplos y clases (y en función de la aplicación potencialmente nuevas tareas). La opción más sencilla para manejar esto sería generar un .zip con nuestros datos, ponerle un nombre (por ejemplo, mnist-v1.0) y guardarlo en algún servidor al cual puedan acceder los ingeniero de deep learning para entrenar modelos. Lo mismo podríamos hacer en el software 1.0 con nuestro código (y durante mucho tiempo así se hizo, incluso quizás hay empresas que aún lo hacen 😂) sin embargo hace tiempo que aprendimos que el uso de herramientas de control de versión son mucho más útiles y eficaces. El ejemplo principal es git. Así pues, para manejar nuestros datos (y más adelante modelos, métricas e incluso pipelines de entrenamiento) usaremos una herramienta de control de versión específica para trabajar con grandes datos en entornos de machine learning conocida como dvc. dvc trabaja en conjunto con git, así que lo primero que necesitaremos será un repositorio de git, que puedes alojar en Github, para manejar el proyecto.\\n\\nEn mi caso he creado este repo que usaré durante toda la serie de posts.\\n\\nPuedes instalar dvc con el siguiente comando:\\npip install dvc', metadata={'source': '087_dlops_intro.txt'})]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'que es el PBDL?'\n",
    "\n",
    "docs = vectorstore.similarity_search(query, k=3)\n",
    "\n",
    "docs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QA pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The LLM model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez preparados los datos, procedemos a instanciar el LLM que queramos usar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/.local/lib/python3.10/site-packages/langchain/llms/openai.py:171: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/home/juan/.local/lib/python3.10/site-packages/langchain/llms/openai.py:716: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain import HuggingFacePipeline, HuggingFaceHub, OpenAI\n",
    "import torch\n",
    "\n",
    "model = \"tiiuae/falcon-40b-instruct\"\n",
    "\n",
    "# modelos HF en local\n",
    "# llm = HuggingFacePipeline.from_model_id(\n",
    "#     model_id=model, \n",
    "#     task=\"text-generation\", \n",
    "#     model_kwargs={\n",
    "#         \"max_length\": 2048, # debe incluir documentos\n",
    "#         'device_map': 'auto',\n",
    "#         'trust_remote_code': True,\n",
    "#         'torch_dtype': torch.bfloat16\n",
    "# \t}\n",
    "# )\n",
    "\n",
    "# modelos HF en la nube\n",
    "# llm = HuggingFaceHub(repo_id=model, model_kwargs={\"temperature\": 0.1, \"max_length\": 2048})\n",
    "\n",
    "# modelos OpenAI\n",
    "llm = OpenAI(model_name='gpt-3.5-turbo', temperature=0, openai_api_key=os.environ['OPENAI_API_KEY'], max_tokens=256)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opcionalmente, podemos modificar los prompts para que se adapten mejor a nuestro caso de uso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "# este es el prompt que se usará para generar las respuestas\n",
    "\n",
    "template = \"\"\"Dado el siguiente contexto, reponde la pregunta.\n",
    "Si no sabes la respuesta, responde con \"No lo sé\". \n",
    "No inventes respuestas.\n",
    "Responde siempre en español.\n",
    "\n",
    "Contexto:\n",
    "\n",
    "{context} \n",
    "\n",
    "Pregunta:\n",
    "\n",
    "{question}\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=['context', 'question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# este es el prompt que se usará cuando usemos contexto de chat (el prompt anterior se ejectuará después)\n",
    "\n",
    "template = \"\"\"Dado el siguiente historial de conversación, reformula la pregunta de forma que el modelo pueda responderla:\n",
    "\n",
    "Historial:\n",
    "\n",
    "{chat_history}\n",
    "\n",
    "Pregunta:\n",
    "\n",
    "{question}\n",
    "\n",
    "Progunta reformulada:\"\"\"\n",
    "\n",
    "condense_question_prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos la `chain`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm, \n",
    "    vectorstore.as_retriever(search_kwargs={'k': 1}), \n",
    "    return_source_documents=True, \n",
    "    condense_question_prompt=condense_question_prompt, \n",
    "    combine_docs_chain_kwargs={'prompt': prompt}\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'El PBDL es el uso del Deep Learning (redes neuronales) para simulación física, en concreto, se centra en CFD: Computational Fluid Dynamics, el campo de la física que se enfoca en la simulación de fluidos para aplicaciones de aerodinámica, combustión, etc.'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history = []\n",
    "query = \"Que es el PBDL?\"\n",
    "result = qa({\"question\": query, \"chat_history\": chat_history})\n",
    "result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['080_pbdl_intro.txt']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[source.metadata['source'] for source in result['source_documents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'El uso del PBDL en la simulación de fluidos para aplicaciones de aerodinámica, combustión, etc. supone una revolución y acelerará, a la vez que abaratará, todo el proceso de diseño de vehículos, dando como resultado vehículos más eficientes, que viajen más rápido consumiendo y contaminando menos.'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.append((query, result[\"answer\"]))\n",
    "query = \"Que ventajas ofrece?\"\n",
    "result = qa({\"question\": query, \"chat_history\": chat_history})\n",
    "result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['080_pbdl_intro.txt']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[source.metadata['source'] for source in result['source_documents']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya lo tenemos todo listo para implementar una API con la que interactuar con el blog a través d elenguaje natural (ver script adjunto)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ideas de mejoras"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Agregar transcripciones de vídeos de youtube\n",
    "- Agregar funcionalidad de voz\n",
    "- Automatizar ETL (cronjob)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
